{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  \\\n",
       "0               Data scientist    \n",
       "1              Data Scientist I   \n",
       "2  Data Scientist - Entry Level   \n",
       "3                Data Scientist   \n",
       "4                Data Scientist   \n",
       "\n",
       "                                         description  \n",
       "0  b\"<div><div>Job Requirements:</div><ul><li><p>...  \n",
       "1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...  \n",
       "2  b'<div><p>As a Data Scientist you will be work...  \n",
       "3  b'<div class=\"jobsearch-JobMetadataHeader icl-...  \n",
       "4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Load data\n",
    "\n",
    "data = ('./data/job_listings.csv')\n",
    "df= pd.read_csv(data, usecols=['title', 'description'])[['title', 'description']]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Job Requirements:\\nConceptual understanding in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Job Description\\n\\nAs a Data Scientist 1, you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>As a Data Scientist you will be working on con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$4,969 - $6,756 a monthContractUnder the gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Location: USA \\xe2\\x80\\x93 multiple locations\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  \\\n",
       "0               Data scientist    \n",
       "1              Data Scientist I   \n",
       "2  Data Scientist - Entry Level   \n",
       "3                Data Scientist   \n",
       "4                Data Scientist   \n",
       "\n",
       "                                         description  \n",
       "0  Job Requirements:\\nConceptual understanding in...  \n",
       "1  Job Description\\n\\nAs a Data Scientist 1, you ...  \n",
       "2  As a Data Scientist you will be working on con...  \n",
       "3  $4,969 - $6,756 a monthContractUnder the gener...  \n",
       "4  Location: USA \\xe2\\x80\\x93 multiple locations\\...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "\n",
    "# define function for cleaning up the description column\n",
    "\n",
    "def clean_description(df):\n",
    "    df = df.copy()\n",
    "    df['description'] = df['description'].str.replace('b\"', '')\n",
    "    df['description'] = df['description'].str.replace(\"b'\", '')\n",
    "    df = df.applymap(lambda text: BeautifulSoup(text, 'html.parser').get_text())\n",
    "    return df\n",
    "\n",
    "df = clean_description(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Job Requirements: Conceptual understanding in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Job Description  As a Data Scientist 1, you wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>As a Data Scientist you will be working on con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$4,969 - $6,756 a monthContractUnder the gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Location: USA     multiple locations + years o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  \\\n",
       "0               Data scientist    \n",
       "1              Data Scientist I   \n",
       "2  Data Scientist - Entry Level   \n",
       "3                Data Scientist   \n",
       "4                Data Scientist   \n",
       "\n",
       "                                         description  \n",
       "0  Job Requirements: Conceptual understanding in ...  \n",
       "1  Job Description  As a Data Scientist 1, you wi...  \n",
       "2  As a Data Scientist you will be working on con...  \n",
       "3  $4,969 - $6,756 a monthContractUnder the gener...  \n",
       "4  Location: USA     multiple locations + years o...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create function to remove unicode using regex\n",
    "\n",
    "def remove_unicode(df):\n",
    "    df = df.copy()\n",
    "    df['description'] = df['description'].str.replace(r'(\\\\(x|n)[a-z0-9]{0,2})', ' ')\n",
    "    return df\n",
    "\n",
    "df = remove_unicode(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Job Description  -10 years hands-on experience in forecasting, Machine learning, and/or optimization modeling, and simulation.Working knowledge of predictive modeling and ML tools (scikit, R)Experience with data acquisition tools (e.g. SQL, Apache Spark etc.), large datasets (Hadoop) and data miningProgramming language (Java, scripting language like Python.Good understanding of NLP conceptsHave understanding of machine learning conceptsHave understanding of Hadoop (specifically HIVE/HDFS/Kafka)Fine on programming concepts     pythonStronger skills on image analysis and more experience in Machine Learning / Deep Learning  Qualifications  ll  Additional Information  All your information will be kept confidential according to EEO guidelines.'\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random check on description\n",
    "\n",
    "df.loc[42, 'description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>At YETI, we believe that time spent outdoors m...</td>\n",
       "      <td>[at, YETI, -PRON-, believe, that, time, spend,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2019 University Graduate - Data Scientist - Po...</td>\n",
       "      <td>About Uber We   re changing the way people thi...</td>\n",
       "      <td>[about, Uber, -PRON-,   , re, change, the, way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Associate Data Scientist – Premium Analytics</td>\n",
       "      <td>As Spotify Premium swells to over 96M subscrib...</td>\n",
       "      <td>[as, Spotify, Premium, swell, to, over, 96, M,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Data Scientist - Machine Learning, AdTech</td>\n",
       "      <td>At Uber, we ignite opportunity by setting the ...</td>\n",
       "      <td>[at, Uber, -PRON-, ignite, opportunity, by, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Overview Our Data Science department is seekin...</td>\n",
       "      <td>[overview, -PRON-, Data, Science, department, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "333                                     Data Scientist   \n",
       "77   2019 University Graduate - Data Scientist - Po...   \n",
       "13        Associate Data Scientist – Premium Analytics   \n",
       "64           Data Scientist - Machine Learning, AdTech   \n",
       "383                           Associate Data Scientist   \n",
       "\n",
       "                                           description  \\\n",
       "333  At YETI, we believe that time spent outdoors m...   \n",
       "77   About Uber We   re changing the way people thi...   \n",
       "13   As Spotify Premium swells to over 96M subscrib...   \n",
       "64   At Uber, we ignite opportunity by setting the ...   \n",
       "383  Overview Our Data Science department is seekin...   \n",
       "\n",
       "                                                tokens  \n",
       "333  [at, YETI, -PRON-, believe, that, time, spend,...  \n",
       "77   [about, Uber, -PRON-,   , re, change, the, way...  \n",
       "13   [as, Spotify, Premium, swell, to, over, 96, M,...  \n",
       "64   [at, Uber, -PRON-, ignite, opportunity, by, se...  \n",
       "383  [overview, -PRON-, Data, Science, department, ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "\n",
    "# Define stop_words, add Data Science on list of stop_words\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "stop_words = nlp.Defaults.stop_words.union(['data', 'science'])\n",
    "\n",
    "# extract tokens\n",
    "df['tokens'] = df['description'].apply(lambda x: [token.lemma_ for token in nlp(x) \n",
    "                                                  if (token not in stop_words)\n",
    "                                                 and (token.is_punct !=True)])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02115</th>\n",
       "      <th>03</th>\n",
       "      <th>0356</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>062</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zogsports</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8731 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  02115  03  0356  04  05  062  06366  08  ...  zero  zeus  zf  \\\n",
       "0   0    0      0   0     0   0   0    0      0   0  ...     0     0   0   \n",
       "1   0    0      0   0     0   0   0    0      0   0  ...     0     0   0   \n",
       "2   0    0      0   0     0   0   0    0      0   0  ...     0     0   0   \n",
       "3   0    0      0   0     0   0   0    0      0   0  ...     0     0   0   \n",
       "4   0    0      0   0     0   0   0    0      0   0  ...     0     0   0   \n",
       "\n",
       "   zheng  zillow  zogsports  zones  zoom  zuckerberg  zurich  \n",
       "0      0       0          0      0     0           0       0  \n",
       "1      0       0          0      0     0           0       0  \n",
       "2      0       0          0      0     0           0       0  \n",
       "3      1       0          0      0     0           0       0  \n",
       "4      0       0          0      0     0           0       0  \n",
       "\n",
       "[5 rows x 8731 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "\n",
    "dtm = vect.fit_transform(df['description'])\n",
    "dtm_df = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
    "dtm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import squarify\n",
    "\n",
    "top20_words = dtm_df.sum().sort_values(ascending=False)\n",
    "squarify.plot(sizes=top20_words.values[:20], label=top20_words.index[:20], alpha=0.8)\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>04</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1079302</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>125</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yeti</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>yrs</th>\n",
       "      <th>zenreach</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zf</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   04   10  100  1079302   11   12  125   14  ...  yes  yeti  york  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  ...  0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  ...  0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  ...  0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  ...  0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0      0.0  0.0  0.0  0.0  0.0  ...  0.0   0.0   0.0   \n",
       "\n",
       "   young  yrs  zenreach  zeus   zf  zillow  zurich  \n",
       "0    0.0  0.0       0.0   0.0  0.0     0.0     0.0  \n",
       "1    0.0  0.0       0.0   0.0  0.0     0.0     0.0  \n",
       "2    0.0  0.0       0.0   0.0  0.0     0.0     0.0  \n",
       "3    0.0  0.0       0.0   0.0  0.0     0.0     0.0  \n",
       "4    0.0  0.0       0.0   0.0  0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate vectorizer object\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# create vocab and get word counts per doc\n",
    "dtm = tfidf.fit_transform(df['description'])\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# fit on DTM\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "nn.fit(dtm)\n",
    "\n",
    "ideal_ds_job = [\"\"\"\n",
    "Ideally I would love to work on Business Process Outsourcing industry or a\n",
    "Customer Experience department. Since my experience goes beyong 10 years in\n",
    "Customer Service and analyzing Net Promoter Score, Customer Satisfaction, and\n",
    "Customer Service Quality Assurance data. I would like to predict customer ratings\n",
    "based on customer service performance metrics like handle time, first call resolution,\n",
    "and other key performance indicators. I would also like to predict CSAT performance\n",
    "of agents based on their soft and technicals skills, as well as performance\n",
    "behaviors.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.26159488, 1.26159488, 1.26159508, 1.28441963, 1.28633017]]),\n",
       " array([[223, 420, 105, 361, 415]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = tfidf.transform(ideal_ds_job)\n",
    "\n",
    "# query using kneighbors\n",
    "nn.kneighbors(query.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Uber, we ignite opportunity by setting the world in motion. We take on big problems to help drivers, riders, delivery partners, and eaters get moving in more than 600 cities around the world.  We welcome people from all backgrounds who seek the opportunity to help build a future where everyone and everything can move independently. If you have the curiosity, passion, and collaborative spirit, work with us, and let   s move the world forward, together. About The Role  Uber   s Customer Obsession Data Science team is looking for world class data scientists to join the team, a group responsible for ensuring every Uber customer support experience is world-class. Specifically, this team works to build self-service technology and processes that are deeply integrated with the Uber customer support experience, making it easy for our customers and customer support representatives to get to the right outcome, faster. They   re also responsible for building the models and algorithms that help Uber customers answer their own questions or, even better, avoid the need for a customer support experience at all. To achieve these goals, our team is looking for data scientists with diverse experience in areas such as Natural Language Processing (NLP), Machine Learning, and conversational agents. Responsibilities  As data scientists on the Customer Obsession Data Science team, we are responsible for owning end-to-end development of data products and solutions.  Example Products Enabling automated resolution of customer contacts providing a delightful user experience to both customers and support agents Building rich chat experiences in a variety of products for riders, drivers, eaters to help users solve their support needs with as little friction as possible Predicting customer intent via text and mobile events and leverage these signals to provide predictive and proactive customer experiences  Skills MS or PhD in computer science, statistics, or a quantitative domain + years professional experience (post-graduation) delivering, scaling, and leading highly successful and innovative machine learning products Demonstrable proficiency in coding (Python, Spark, or R preferred) and programming concepts Know core ML concepts (i.e. feature discovery and engineering, model validation, retraining strategies) like the back of your hand Substantial depth in at least a few key areas of NLP such as classic NLP approaches (i.e. LDA, TF-IDF), embeddings based techniques (i.e. word2vec, doc2vec, GloVe), neural architectures (i.e. CNN, RNN, attention), variational inference techniques (LDA). Familiarity with experimentation and statistical principles (i.e. confidence intervals, sampling distributions, Bayes    Theorem) A commitment to learning - We want someone who seeks to deliver impact, but also invests in themselves and others. A strong communicator who can partner with others to set a vision and then collaborate to deliver impactful results that are well explained.'\n",
      "-----\n",
      "At Uber, we ignite opportunity by setting the world in motion. We take on big problems to help drivers, riders, delivery partners, and eaters get moving in more than 600 cities around the world.  We welcome people from all backgrounds who seek the opportunity to help build a future where everyone and everything can move independently. If you have the curiosity, passion, and collaborative spirit, work with us, and let   s move the world forward, together. About The Role  Uber   s Customer Obsession Data Science team is looking for world class data scientists to join the team, a group responsible for ensuring every Uber customer support experience is world-class. Specifically, this team works to build self-service technology and processes that are deeply integrated with the Uber customer support experience, making it easy for our customers and customer support representatives to get to the right outcome, faster. They   re also responsible for building the models and algorithms that help Uber customers answer their own questions or, even better, avoid the need for a customer support experience at all. To achieve these goals, our team is looking for data scientists with diverse experience in areas such as Natural Language Processing (NLP), Machine Learning, and conversational agents. Responsibilities  As data scientists on the Customer Obsession Data Science team, we are responsible for owning end-to-end development of data products and solutions.  Example Products Enabling automated resolution of customer contacts providing a delightful user experience to both customers and support agents Building rich chat experiences in a variety of products for riders, drivers, eaters to help users solve their support needs with as little friction as possible Predicting customer intent via text and mobile events and leverage these signals to provide predictive and proactive customer experiences  Skills MS or PhD in computer science, statistics, or a quantitative domain + years professional experience (post-graduation) delivering, scaling, and leading highly successful and innovative machine learning products Demonstrable proficiency in coding (Python, Spark, or R preferred) and programming concepts Know core ML concepts (i.e. feature discovery and engineering, model validation, retraining strategies) like the back of your hand Substantial depth in at least a few key areas of NLP such as classic NLP approaches (i.e. LDA, TF-IDF), embeddings based techniques (i.e. word2vec, doc2vec, GloVe), neural architectures (i.e. CNN, RNN, attention), variational inference techniques (LDA). Familiarity with experimentation and statistical principles (i.e. confidence intervals, sampling distributions, Bayes    Theorem) A commitment to learning - We want someone who seeks to deliver impact, but also invests in themselves and others. A strong communicator who can partner with others to set a vision and then collaborate to deliver impactful results that are well explained.'\n",
      "-----\n",
      "Data Scientist duties will typically be focused on the customer   s business analytics, metrics collection, and analysis efforts to assist the customer   s management team in process improvement .'\n",
      "-----\n",
      "Los Gatos, California Science and Analytics Netflix is a global leader in entertainment with over 130 million members in 190 countries. While we are making great strides in becoming the biggest and most data-driven studio the world has ever seen, we are also continuously innovating our ways to promote better customer experience. Customer Service (CS) is one of the few verticals in which we directly collect customer feedbacks across the globe (via phone, chat and social media). Using data from a global network of call centers, extensive self-help articles we solve customer problems and aim to improve our product experience before problems arise.  We are looking for a highly motivated Senior Data Scientist that will help bring our customer experience to the next level. You will be Leveraging NLP to uncover deeper consumer insights from phone contacts, live chat, and social media interactions to inform product initiatives in improving the customer experience. Building machine learning models to optimize our customer support process and personalize our customer   s self-help experience. Working with a diverse set of stakeholders across operation and product, serving as a strategic partner to define high impact analytical problems and find innovative ways to solve these problems via data, machine learning solutions and experimentation. Partnering with other research scientists on solving a broader set of NLP challenges across Netflix. Qualifications: Ph.D. in Computer Science, Statistics, Physics, or related quantitative field Solid experience with Natural Language Processing (NLP). Strong fundamental knowledge of regression, decision trees, pattern recognition, probability theory, neural networks. Expert in Python, or another scripting language (R, Perl); command line usage Extensive experience with SQL Experience working directly with cross-functional teams such as executive leadership, operations, product management, and technology. Excellent communication skills: written, verbal and presentation skills Experience in causal inference is a strong plus Fluency in a foreign language a strong plus'\n",
      "-----\n",
      "Temporary, Internship The Marketing Data Scientist Intern will support the various exciting data initiatives within the company aiming to use advanced modeling and statistical methods to gain insight, make scientifically-informed decisions, and improve the company   s overall operations and customer experience. Intern will work with Insights Team to analyze: customer behaviors, market analysis, service and product preferences, marketing response, and selection criteria modeling and analysis, etc. Intern may also perform analyses of customer behavior leveraging a combination of internal and external customer data. They must have strong verbal and written communication skills to engage both technical and non-technical audiences and must be able to work across business lines with a variety of stakeholders. The Intern job duties may include but are not limited to: Performing analyses of customer related data on behalf of the Insights team to define, analyze, and deliver recommendations based on business objectives. Develop business process that work across multiple business groups. Create credibility with leaders and stakeholders by presenting data clearly and concisely  Ability to develop credibility with leadership and stakeholders by presenting data clearly and concisely Background in quantitative analysis, including statistics, modeling, and data mining very helpful. Statistical software knowledge (SQL, R, Python, Scala, etc.) needed'\n"
     ]
    }
   ],
   "source": [
    "# most relevant results\n",
    "print(df.loc[223]['description'])\n",
    "print('-----')\n",
    "print(df.loc[420]['description'])\n",
    "print('-----')\n",
    "print(df.loc[105]['description'])\n",
    "print('-----')\n",
    "print(df.loc[361]['description'])\n",
    "print('-----')\n",
    "print(df.loc[415]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
