{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOMBkFKn6uEK"
   },
   "source": [
    "# Topic Modeling (Prepare)\n",
    "\n",
    "On Monday we talked about summarizing your documents using just token counts. Today, we're going to learn about a much more sophisticated approach - learning 'topics' from documents. Topics are a latent structure. They are not directly observable in the data, but we know they're there by reading them.\n",
    "\n",
    "> **latent**: existing but not yet developed or manifest; hidden or concealed.\n",
    "\n",
    "## Use Cases\n",
    "Primary use case: what the hell are your documents about? Who might want to know that in industry - \n",
    "* Identifying common themes in customer reviews\n",
    "* Discovering the needle in a haystack \n",
    "* Monitoring communications (Email - State Department) \n",
    "\n",
    "## Learning Objectives\n",
    "*At the end of the lesson you should be able to:*\n",
    "* Part 0: Warm-Up\n",
    "* Part 1: Describe how an LDA Model works\n",
    "* Part 2: Estimate a LDA Model with Gensim\n",
    "* Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxH0cRGX6uEL"
   },
   "source": [
    "# Part 0: Warm-Up\n",
    "How do we do a grid search? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFjplZ7r3Lyk"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnyNg8sQ6uEL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "boKWVkRz6uEO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 1788\n",
      "Testing Samples: 1189\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "categories = ['sci.electronics',\n",
    "              'rec.sport.baseball',\n",
    "              'rec.sport.hockey']\n",
    "# Load training data\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', \n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "# Load testing data\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', \n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     categories=categories)\n",
    "print(f'Training Samples: {len(newsgroups_train.data)}')\n",
    "print(f'Testing Samples: {len(newsgroups_test.data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPpukADi7Ofv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g9Jhb3j-7_e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec.sport.baseball', 'rec.sport.hockey', 'sci.electronics']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JbVoIoMm8HbR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<lots of pretty good stuff about how the huge towers near most nuclear\\npower plants are there to cool the used steam back into near ambient\\ntemperature water deleted>\\n\\n\\n\\n    as a point of info, some of the early nuclear power plants in this\\ncountry used the fission pile as a first stage to get the water hot, and\\nthen had a second stage -fossil fuel- step to get the water (actually\\nsteam) VERY HOT.\\n\\n   I remember seeing this at Con Edison's Indian Point #1 power plant,\\nwhich is about 30 miles north of NYC, and built more or less 1958.\\n\\n\\ndannyb@panix.com\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['data'][1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-39zg9a6uEQ"
   },
   "source": [
    "### GridSearch on Just Classifier\n",
    "* Fit the vectorizer and prepare BEFORE it goes into the gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2q3NmHEo6uEQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1788, 19009)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate vectorizer\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "# Transform the training data\n",
    "X_train = vect.fit_transform(newsgroups_train['data'])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OfA7KNQ6uEU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   13.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'min_samples_leaf': [1, 2, 5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_1 = {\n",
    "    'min_samples_leaf': [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "# Instantiate classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# GridSearch\n",
    "gs1 = GridSearchCV(clf, params_1, cv=5, n_jobs=-1, verbose=1)\n",
    "gs1.fit(X_train, newsgroups_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8439572477035506"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDkMaXvG83Zt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19009)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = vect.transform([\"The new york yankees are the best team in the region.\"])\n",
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMq_hw5W6uEX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.predict(test_sample)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.sport.hockey'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['target_names'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdVTuXKl6uEZ"
   },
   "source": [
    "### GridSearch with BOTH the Vectoizer & Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97TjUtoI6uEZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   18.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acce...\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=42,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (10, None), 'vect__min_df': (2, 5),\n",
       "                         'vect__stop_words': (None, 'english')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Create a pipeline with a vectorize and a classifier\n",
    "# 2. Use Grid Search to optimize the entire pipeline\n",
    "pipe = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "params_2 = {\n",
    "    'vect__stop_words': (None, 'english'),\n",
    "    'vect__min_df': (2,5),\n",
    "    'clf__max_depth': (10, None)\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(pipe, params_2, cv=5, n_jobs=-1, verbose=1)\n",
    "gs2.fit(newsgroups_train['data'], newsgroups_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858508990188254"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': None, 'vect__min_df': 2, 'vect__stop_words': 'english'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdIE67Us6uEc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gs2.predict([\"The new york yankees are the best team in the region.\"])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhcb5G0W-Dch"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.sport.baseball'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['target_names'][pred[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2R2ACd36uEd"
   },
   "source": [
    "Advantages to using GS with the Pipe:\n",
    "* Allows us to make predictions on raw text increasing reproducibility. :)\n",
    "* Allows us to tune the parameters of the vectorizer along side the classifier. :D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbZjG6U86uEe"
   },
   "source": [
    "# Part 1: Describe how an LDA Model works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMzU-XOM3LzW"
   },
   "source": [
    "[Your Guide to Latent Dirichlet Allocation](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d)\n",
    "\n",
    "[LDA Topic Modeling](https://lettier.com/projects/lda-topic-modeling/)\n",
    "\n",
    "[Topic Modeling with Gensim](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yPIlE_IeF0cX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# Download spacy model\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qapChu_UGBFc"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaMsy1XAGLxc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1788, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'content': newsgroups_train['data'],\n",
    "    'target': newsgroups_train['target'],\n",
    "    'target_names': [newsgroups_train['target_names'][i] for i in newsgroups_train['target']]\n",
    "})\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>Is it just me, or does Bichette look totally lost in the outfield?  He \\nmisplayed Martinez fly-out into a double against the Expos, misplayed\\nAlou's single into a triple (Alou tagged out at 3rd after over-sliding \\nthe bag) and now he misplays another out into a 3 run triple...add in his\\nwonderful batting average and we have one heck of a player!</td>\n",
       "      <td>0</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>\\ne,\\n\\nIf memory serves me well, Alicea hit it, and damn near tied the game.\\nTorre obviously knows his players better than you do. \\n\\n\\nSee y'all at the ballyard\\nGo Braves\\nChop Chop\\n\\nMichael Mule'\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>\\nAmusing, isn't it?  Seems only the SDCNs realize how much baseball is\\na *team* game, combining efforts from every player for the win.\\n\\nConsider the Red Sox game last night.  The Sox won 4-3 in the bottom\\nof the 13th.  Who won the game?\\n\\n-Clemens pitched a strong nine (?) innings, allowing only two runs.\\n-Ryan pitched a couple shutout innings, though he needed some excellent\\n defensive plays behind him to do so.\\n-Quantrill pitched a couple of innings, gave up the go-ahead run, and\\n got credited with the win when the Sox scored two in the bottom of\\n the inning.\\n\\nLooks like a team effort to me!  Yet only Quantrill got credit for\\nthe win.\\n\\nHow about the offense?\\n-Dawson and Vaughn hit (I think) HRs early in the game.  Without either\\n one, the Sox would have lost in nine.\\n-Quintana led off the 13th with a solid single.\\n-Zupcic pinch-ran for Quintana, providing the speed to go from first\\n to third when...\\n-Cooper ripped a *second* single in the inning.\\n-Melvin avoided the DP, getting the run home with a sac fly.  Not much of\\n a help, but it was something.\\n-Scrub Richardson then hit a double, scoring the speedy Cooper all the\\n way from first!  (Hill's lack of defense helped.)\\n\\nCooper and Zupcic were credited with runs, Melvin and Richardson were\\ncredited with RBIs.  But it seems to me that it was Quintana's hit\\nthat set up the whole inning!  And did Melvin really contribute as\\nmuch as Richardson?\\n\\nFurthermore, people seem to consider RBIs to be more significant than\\nruns.  Did Melvin contribute more than Cooper?  Cooper provided the\\ngame-winning baserunner, and moved the tying run to third base with\\nonly one out!\\n\\nAssigning credit based on Runs and RBIs is clearly ridiculous.  You\\ncan argue that OBP and SLG don't show you who came through in the\\nclutch, but R&amp;RBI don't do any better.  At least OBP and SLG don't\\n*claim* to try to tell you that.\\n\\nHere's to the Red Sox who contributed to last night's victory.\\nAll 20 of them!</td>\n",
       "      <td>0</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         content  \\\n",
       "1744  Is it just me, or does Bichette look totally lost in the outfield?  He \\nmisplayed Martinez fly-out into a double against the Expos, misplayed\\nAlou's single into a triple (Alou tagged out at 3rd after over-sliding \\nthe bag) and now he misplays another out into a 3 run triple...add in his\\nwonderful batting average and we have one heck of a player!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "510   \\ne,\\n\\nIf memory serves me well, Alicea hit it, and damn near tied the game.\\nTorre obviously knows his players better than you do. \\n\\n\\nSee y'all at the ballyard\\nGo Braves\\nChop Chop\\n\\nMichael Mule'\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "1731  \\nAmusing, isn't it?  Seems only the SDCNs realize how much baseball is\\na *team* game, combining efforts from every player for the win.\\n\\nConsider the Red Sox game last night.  The Sox won 4-3 in the bottom\\nof the 13th.  Who won the game?\\n\\n-Clemens pitched a strong nine (?) innings, allowing only two runs.\\n-Ryan pitched a couple shutout innings, though he needed some excellent\\n defensive plays behind him to do so.\\n-Quantrill pitched a couple of innings, gave up the go-ahead run, and\\n got credited with the win when the Sox scored two in the bottom of\\n the inning.\\n\\nLooks like a team effort to me!  Yet only Quantrill got credit for\\nthe win.\\n\\nHow about the offense?\\n-Dawson and Vaughn hit (I think) HRs early in the game.  Without either\\n one, the Sox would have lost in nine.\\n-Quintana led off the 13th with a solid single.\\n-Zupcic pinch-ran for Quintana, providing the speed to go from first\\n to third when...\\n-Cooper ripped a *second* single in the inning.\\n-Melvin avoided the DP, getting the run home with a sac fly.  Not much of\\n a help, but it was something.\\n-Scrub Richardson then hit a double, scoring the speedy Cooper all the\\n way from first!  (Hill's lack of defense helped.)\\n\\nCooper and Zupcic were credited with runs, Melvin and Richardson were\\ncredited with RBIs.  But it seems to me that it was Quintana's hit\\nthat set up the whole inning!  And did Melvin really contribute as\\nmuch as Richardson?\\n\\nFurthermore, people seem to consider RBIs to be more significant than\\nruns.  Did Melvin contribute more than Cooper?  Cooper provided the\\ngame-winning baserunner, and moved the tying run to third base with\\nonly one out!\\n\\nAssigning credit based on Runs and RBIs is clearly ridiculous.  You\\ncan argue that OBP and SLG don't show you who came through in the\\nclutch, but R&RBI don't do any better.  At least OBP and SLG don't\\n*claim* to try to tell you that.\\n\\nHere's to the Red Sox who contributed to last night's victory.\\nAll 20 of them!   \n",
       "\n",
       "      target        target_names  \n",
       "1744  0       rec.sport.baseball  \n",
       "510   0       rec.sport.baseball  \n",
       "1731  0       rec.sport.baseball  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 0)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "na2bkOcFGter"
   },
   "outputs": [],
   "source": [
    "# For reference on regex: https://docs.python.org/3/library/re.html\n",
    "\n",
    "# From 'content' column: \n",
    "# 1. Remove new line characters\n",
    "df['clean_text'] = df['content'].apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "\n",
    "# 2. Remove Emails\n",
    "df['clean_text'] = df['clean_text'].apply(lambda x: re.sub('From: \\S+@\\S+', '', x))\n",
    "\n",
    "# 3. Remove non-alphanumeric characters\n",
    "df['clean_text'] = df['clean_text'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
    "\n",
    "# 4. Remove extra whitespace \n",
    "df['clean_text'] = df['clean_text'].apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2prKILFo3Lzg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>It was my impression watching the Mets &amp; Rockies that umpires were\\ncalling strikes above the belt, too, but not as far up as the letters.\\nIt would be nice if this were the case.</td>\n",
       "      <td>0</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>It was my impression watching the Mets Rockies that umpires were calling strikes above the belt too but not as far up as the letters It would be nice if this were the case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>\\n\\nGretzky, Lemieux, Gilmour etc do not play the role of checking centreman.\\nThey play an offensive role as opposed to a defensive one.  If they\\nwere used as defensive centres it would be a waste of their offensive\\nabilities. \\n\\nWhen you compare Gretzky et al to Jarvis, Gainey etc you are comparing \\napples and oranges.  It is like me telling you that Felix Potvin isn't \\nvery good because a team would be better if the had Lemieux instead of\\nhim.  Sure Lemieux is a better player, but he is a different type of\\nplayer.  For a team to be successful, they need to have all types of\\nplayers- this includes defensive forwards.\\n\\nWhen compared with other defensive forwards, Bob Gainey is the greatest\\ndefensive forward ever.  He is the player who's talents best suited being\\na defensive forward- who completely dominated the game when he played.\\n\\nMaybe if a more talented player such as Gretzky had decided to waste his\\noffensive talents and play defensively, he could have been a better\\ndefensive forward, but he wasn't.\\n\\nBob Gainey is the best defensive forward that has ever played hockey.</td>\n",
       "      <td>1</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Gretzky Lemieux Gilmour etc do not play the role of checking centreman They play an offensive role as opposed to a defensive one If they were used as defensive centres it would be a waste of their offensive abilities When you compare Gretzky et al to Jarvis Gainey etc you are comparing apples and oranges It is like me telling you that Felix Potvin isn t very good because a team would be better if the had Lemieux instead of him Sure Lemieux is a better player but he is a different type of player For a team to be successful they need to have all types of players this includes defensive forwards When compared with other defensive forwards Bob Gainey is the greatest defensive forward ever He is the player who s talents best suited being a defensive forward who completely dominated the game when he played Maybe if a more talented player such as Gretzky had decided to waste his offensive talents and play defensively he could have been a better defensive forward but he wasn t Bob Gainey is the best defensive forward that has ever played hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>\\n\\tBeing a proud BU alumnus, I'd like to get a list of BU players in \\nthe NHL so I can keep an eye on their progress. A lot of Terriers are\\ngraduating this year so I hope to see them soon in the NHL. If somebody\\ncould post or send me a list, I'd appreciate it. Please note if the player\\ngraduated from here or not.\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Being a proud BU alumnus I d like to get a list of BU players in the NHL so I can keep an eye on their progress A lot of Terriers are graduating this year so I hope to see them soon in the NHL If somebody could post or send me a list I d appreciate it Please note if the player graduated from here or not</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    content  \\\n",
       "1223  It was my impression watching the Mets & Rockies that umpires were\\ncalling strikes above the belt, too, but not as far up as the letters.\\nIt would be nice if this were the case.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "130   \\n\\nGretzky, Lemieux, Gilmour etc do not play the role of checking centreman.\\nThey play an offensive role as opposed to a defensive one.  If they\\nwere used as defensive centres it would be a waste of their offensive\\nabilities. \\n\\nWhen you compare Gretzky et al to Jarvis, Gainey etc you are comparing \\napples and oranges.  It is like me telling you that Felix Potvin isn't \\nvery good because a team would be better if the had Lemieux instead of\\nhim.  Sure Lemieux is a better player, but he is a different type of\\nplayer.  For a team to be successful, they need to have all types of\\nplayers- this includes defensive forwards.\\n\\nWhen compared with other defensive forwards, Bob Gainey is the greatest\\ndefensive forward ever.  He is the player who's talents best suited being\\na defensive forward- who completely dominated the game when he played.\\n\\nMaybe if a more talented player such as Gretzky had decided to waste his\\noffensive talents and play defensively, he could have been a better\\ndefensive forward, but he wasn't.\\n\\nBob Gainey is the best defensive forward that has ever played hockey.   \n",
       "302   \\n\\tBeing a proud BU alumnus, I'd like to get a list of BU players in \\nthe NHL so I can keep an eye on their progress. A lot of Terriers are\\ngraduating this year so I hope to see them soon in the NHL. If somebody\\ncould post or send me a list, I'd appreciate it. Please note if the player\\ngraduated from here or not.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "\n",
       "      target        target_names  \\\n",
       "1223  0       rec.sport.baseball   \n",
       "130   1       rec.sport.hockey     \n",
       "302   1       rec.sport.hockey     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        clean_text  \n",
       "1223  It was my impression watching the Mets Rockies that umpires were calling strikes above the belt too but not as far up as the letters It would be nice if this were the case                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "130   Gretzky Lemieux Gilmour etc do not play the role of checking centreman They play an offensive role as opposed to a defensive one If they were used as defensive centres it would be a waste of their offensive abilities When you compare Gretzky et al to Jarvis Gainey etc you are comparing apples and oranges It is like me telling you that Felix Potvin isn t very good because a team would be better if the had Lemieux instead of him Sure Lemieux is a better player but he is a different type of player For a team to be successful they need to have all types of players this includes defensive forwards When compared with other defensive forwards Bob Gainey is the greatest defensive forward ever He is the player who s talents best suited being a defensive forward who completely dominated the game when he played Maybe if a more talented player such as Gretzky had decided to waste his offensive talents and play defensively he could have been a better defensive forward but he wasn t Bob Gainey is the best defensive forward that has ever played hockey  \n",
       "302   Being a proud BU alumnus I d like to get a list of BU players in the NHL so I can keep an eye on their progress A lot of Terriers are graduating this year so I hope to see them soon in the NHL If somebody could post or send me a list I d appreciate it Please note if the player graduated from here or not                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSW10Cb33Lzk"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkgfv9tc3Lzi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/tqdm/std.py:703: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "# Leverage tqdm for progress_apply\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# If you're on macOS, Linux, or python session executed from Windows Subsystem for Linux (WSL)\n",
    "# conda activate U4-S1-NLP\n",
    "# pip install pandarallel\n",
    "#\n",
    "# from pandarallel import pandarallel\n",
    "# pandarallel.initialize(progress_bar=True)\n",
    "#\n",
    "# df['lemmas'] = df['content'].parallel_apply(get_lemmas)\n",
    "#\n",
    "# Ref: https://github.com/nalepae/pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EBPQXqEKE9P",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1788/1788 [01:08<00:00, 26.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create 'lemmas' column\n",
    "def get_lemmas(x):\n",
    "    lemmas = []\n",
    "    for token in nlp(x):\n",
    "        if (token.is_stop!=True) and (token.is_punct!=True):\n",
    "            lemmas.append(token.lemma_)\n",
    "    return lemmas\n",
    "\n",
    "df['lemmas'] = df['clean_text'].progress_apply(get_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yvsyIpvKBlw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nOh yeah, how come Dino could never take the Caps out of the Patrick\\nDivision?  He choked up 3 games to 1 last year and got swept away in\\nthe second round two years ago.  He rarely, if ever, makes it out of the\\ndivision.\\n\\n\\nSo are the Islanders, but they can still pull it out.  Vancouver has Winnipeg's\\n number, so it really doesn't matter.\\n\\n\\n\\n Kings always seem to go at least 6 or 7, they never play a four or five\\ngame serious.  There's a difference between battling it out and pulling it\\nout, as I take Calgary to pull it out in 7.</td>\n",
       "      <td>1</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>Oh yeah how come Dino could never take the Caps out of the Patrick Division He choked up games to last year and got swept away in the second round two years ago He rarely if ever makes it out of the division So are the Islanders but they can still pull it out Vancouver has Winnipeg s number so it really doesn t matter Kings always seem to go at least or they never play a four or five game serious There s a difference between battling it out and pulling it out as I take Calgary to pull it out in</td>\n",
       "      <td>[oh, yeah, come, Dino, cap, Patrick, Division, choke, game, year, get, sweep, away, second, round, year, ago, rarely, make, division, Islanders, pull, Vancouver, Winnipeg, s, number, doesn, t, matter, king, play, game, s, difference, battle, pull, Calgary, pull]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Does anyone know where Billy Taylor is?  Richmond or Syracuse?  He was taken\\nby the Jays in the Rule V draft, but not kept on the roster.  Baseball Weekly\\nsaid that he was demoted to Syracuse, but a Toronto paper indicated that\\nthe Braves took him back.  Is there an Atlanta fan, or anyone reading this,\\nwho knows?</td>\n",
       "      <td>0</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>Does anyone know where Billy Taylor is Richmond or Syracuse He was taken by the Jays in the Rule V draft but not kept on the roster Baseball Weekly said that he was demoted to Syracuse but a Toronto paper indicated that the Braves took him back Is there an Atlanta fan or anyone reading this who knows</td>\n",
       "      <td>[know, Billy, Taylor, Richmond, Syracuse, take, Jays, Rule, v, draft, keep, roster, Baseball, Weekly, say, demote, Syracuse, Toronto, paper, indicate, Braves, take, Atlanta, fan, read, know]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\nWhy are you fooling around with analog for this job?  A single chip\\nmicro and a crystal will do the job reliably and easily.  An 8748 only\\ncosts about $5.  That and a $1 crystal and you're in business.  Embed\\nthe whole thing in a foam insulated blanket, power it from a solar cell,\\nuse the excess power to heat the assembly during the day and rely\\non the insulation to hold the heat during darkness.  If you don't want\\nto try thermal management, contact someone like ICL and have them cut\\nyou a special low temperature crystal.  It'll cost at most $20.\\n\\nIf you use a single chip micro, you're looking at a parts count of \\nmaybe 7.  A processor, a crystal, two caps on the crystal, a power FET\\nto fire the solenoid a flyback diode and a battery.  This is fewer parts than \\nyou can build an analog timer for and is infinitely more reliable.  Add\\na power zener diode (for heat) and a solar cell and the parts count\\nscreams up to 9.\\n\\nPD assemblers are available for all the common single chip micros.  This\\napplication is so trivial you could even look up the op codes in the \\nprogrammer's guide and create the binary with a hex editor.\\n\\nJohn</td>\n",
       "      <td>2</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>Why are you fooling around with analog for this job A single chip micro and a crystal will do the job reliably and easily An only costs about That and a crystal and you re in business Embed the whole thing in a foam insulated blanket power it from a solar cell use the excess power to heat the assembly during the day and rely on the insulation to hold the heat during darkness If you don t want to try thermal management contact someone like ICL and have them cut you a special low temperature crystal It ll cost at most If you use a single chip micro you re looking at a parts count of maybe A processor a crystal two caps on the crystal a power FET to fire the solenoid a flyback diode and a battery This is fewer parts than you can build an analog timer for and is infinitely more reliable Add a power zener diode for heat and a solar cell and the parts count screams up to PD assemblers are available for all the common single chip micros This application is so trivial you could even look up the op codes in the programmer s guide and create the binary with a hex editor John</td>\n",
       "      <td>[fool, analog, job, single, chip, micro, crystal, job, reliably, easily, cost, crystal, business, Embed, thing, foam, insulate, blanket, power, solar, cell, use, excess, power, heat, assembly, day, rely, insulation, hold, heat, darkness, don, t, want, try, thermal, management, contact, like, ICL, cut, special, low, temperature, crystal, will, cost, use, single, chip, micro, look, part, count, maybe, processor, crystal, cap, crystal, power, FET, fire, solenoid, flyback, diode, battery, few, part, build, analog, timer, infinitely, reliable, add, power, zener, diode, heat, solar, cell, part, count, scream, PD, assembler, available, common, single, chip, micro, application, trivial, look, op, code, programmer, s, guide, create, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nCan anybody name a player who was 'rushed' to the majors (let's, for\\nargument's sake, define \"rushed\" as brought up to the majors for more than\\na cup of coffee prior at age 22 or younger, and performing below\\nexpectations), whose career was damaged by this rushing?  I'm serious; I\\ntend to agree with David that bringing the player up sooner is better, but\\nI'd like to look at players for whom this theory didn't work, if there are\\nany.  I'd prefer players within the last 10 years or so, because then I can\\nlook up their minor league stats.  (It's important to distinguish between\\nplayers who legitimately had careers below what their minor league numbers\\nwould have projected, as opposed to players who were hyped and failed, but\\nactually had careers not out of line with their minor league numbers).  \\n\\nLet's kick it off with an example of a player who was \"rushed\", although\\nthere doesn't seem to have been any damage to his career.  Jay Bell was\\ngiven 135 PAs in the major leagues at age 21, and performed well below what\\nyou would expect from his AAA numbers the same season.  He got 236 PAs the\\nnext year at age 22, and still underperformed.  However, the next year, at\\nage 24, his performance improved, and he won the everyday shortstop job,\\nand has been there ever since.  It's really hard for me to see where he\\nwould have been better off staying in the minor league (where he was\\nperformed quite well in AAA) during this time, rather than being \"rushed\";\\nCleveland might have been better off, I suppose, because they might have\\nbeen less likely to give up on him.\\n\\nYes, if you bring a player up early, he's likely going to struggle.  But\\ndoes that delay the time at which he stops struggling, and starts\\nperforming up to expectations?</td>\n",
       "      <td>0</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>Can anybody name a player who was rushed to the majors let s for argument s sake define rushed as brought up to the majors for more than a cup of coffee prior at age or younger and performing below expectations whose career was damaged by this rushing I m serious I tend to agree with David that bringing the player up sooner is better but I d like to look at players for whom this theory didn t work if there are any I d prefer players within the last years or so because then I can look up their minor league stats It s important to distinguish between players who legitimately had careers below what their minor league numbers would have projected as opposed to players who were hyped and failed but actually had careers not out of line with their minor league numbers Let s kick it off with an example of a player who was rushed although there doesn t seem to have been any damage to his career Jay Bell was given PAs in the major leagues at age and performed well below what you would expect from his AAA numbers the same season He got PAs the next year at age and still underperformed However the next year at age his performance improved and he won the everyday shortstop job and has been there ever since It s really hard for me to see where he would have been better off staying in the minor league where he was performed quite well in AAA during this time rather than being rushed Cleveland might have been better off I suppose because they might have been less likely to give up on him Yes if you bring a player up early he s likely going to struggle But does that delay the time at which he stops struggling and starts performing up to expectations</td>\n",
       "      <td>[anybody, player, rush, major, let, s, argument, s, sake, define, rush, bring, major, cup, coffee, prior, age, young, perform, expectation, career, damage, rush, m, tend, agree, David, bring, player, sooner, well, d, like, look, player, theory, didn, t, work, d, prefer, player, year, look, minor, league, stat, s, important, distinguish, player, legitimately, career, minor, league, number, project, oppose, player, hype, fail, actually, career, line, minor, league, number, let, s, kick, example, player, rush, doesn, t, damage, career, Jay, Bell, give, pas, major, league, age, perform, expect, AAA, number, season, get, pas, year, age, underperform, year, age, performance, improve, win, everyday, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3. With Soderstrom and Roussel, why the hell would the Flyers want to\\n   pick up an older and slumping Roy?\\n\\n(BYW, I could come up with a group of players they'd trade for.... but\\nthey wouldn't be from the same team.)\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>With Soderstrom and Roussel why the hell would the Flyers want to pick up an older and slumping Roy BYW I could come up with a group of players they d trade for but they wouldn t be from the same team</td>\n",
       "      <td>[Soderstrom, Roussel, hell, Flyers, want, pick, old, slump, Roy, BYW, come, group, player, d, trade, wouldn, t, team]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         content  \\\n",
       "0  \\nOh yeah, how come Dino could never take the Caps out of the Patrick\\nDivision?  He choked up 3 games to 1 last year and got swept away in\\nthe second round two years ago.  He rarely, if ever, makes it out of the\\ndivision.\\n\\n\\nSo are the Islanders, but they can still pull it out.  Vancouver has Winnipeg's\\n number, so it really doesn't matter.\\n\\n\\n\\n Kings always seem to go at least 6 or 7, they never play a four or five\\ngame serious.  There's a difference between battling it out and pulling it\\nout, as I take Calgary to pull it out in 7.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "1  Does anyone know where Billy Taylor is?  Richmond or Syracuse?  He was taken\\nby the Jays in the Rule V draft, but not kept on the roster.  Baseball Weekly\\nsaid that he was demoted to Syracuse, but a Toronto paper indicated that\\nthe Braves took him back.  Is there an Atlanta fan, or anyone reading this,\\nwho knows?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "2  \\n\\n\\nWhy are you fooling around with analog for this job?  A single chip\\nmicro and a crystal will do the job reliably and easily.  An 8748 only\\ncosts about $5.  That and a $1 crystal and you're in business.  Embed\\nthe whole thing in a foam insulated blanket, power it from a solar cell,\\nuse the excess power to heat the assembly during the day and rely\\non the insulation to hold the heat during darkness.  If you don't want\\nto try thermal management, contact someone like ICL and have them cut\\nyou a special low temperature crystal.  It'll cost at most $20.\\n\\nIf you use a single chip micro, you're looking at a parts count of \\nmaybe 7.  A processor, a crystal, two caps on the crystal, a power FET\\nto fire the solenoid a flyback diode and a battery.  This is fewer parts than \\nyou can build an analog timer for and is infinitely more reliable.  Add\\na power zener diode (for heat) and a solar cell and the parts count\\nscreams up to 9.\\n\\nPD assemblers are available for all the common single chip micros.  This\\napplication is so trivial you could even look up the op codes in the \\nprogrammer's guide and create the binary with a hex editor.\\n\\nJohn                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "3  \\nCan anybody name a player who was 'rushed' to the majors (let's, for\\nargument's sake, define \"rushed\" as brought up to the majors for more than\\na cup of coffee prior at age 22 or younger, and performing below\\nexpectations), whose career was damaged by this rushing?  I'm serious; I\\ntend to agree with David that bringing the player up sooner is better, but\\nI'd like to look at players for whom this theory didn't work, if there are\\nany.  I'd prefer players within the last 10 years or so, because then I can\\nlook up their minor league stats.  (It's important to distinguish between\\nplayers who legitimately had careers below what their minor league numbers\\nwould have projected, as opposed to players who were hyped and failed, but\\nactually had careers not out of line with their minor league numbers).  \\n\\nLet's kick it off with an example of a player who was \"rushed\", although\\nthere doesn't seem to have been any damage to his career.  Jay Bell was\\ngiven 135 PAs in the major leagues at age 21, and performed well below what\\nyou would expect from his AAA numbers the same season.  He got 236 PAs the\\nnext year at age 22, and still underperformed.  However, the next year, at\\nage 24, his performance improved, and he won the everyday shortstop job,\\nand has been there ever since.  It's really hard for me to see where he\\nwould have been better off staying in the minor league (where he was\\nperformed quite well in AAA) during this time, rather than being \"rushed\";\\nCleveland might have been better off, I suppose, because they might have\\nbeen less likely to give up on him.\\n\\nYes, if you bring a player up early, he's likely going to struggle.  But\\ndoes that delay the time at which he stops struggling, and starts\\nperforming up to expectations?   \n",
       "4  3. With Soderstrom and Roussel, why the hell would the Flyers want to\\n   pick up an older and slumping Roy?\\n\\n(BYW, I could come up with a group of players they'd trade for.... but\\nthey wouldn't be from the same team.)\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "\n",
       "   target        target_names  \\\n",
       "0  1       rec.sport.hockey     \n",
       "1  0       rec.sport.baseball   \n",
       "2  2       sci.electronics      \n",
       "3  0       rec.sport.baseball   \n",
       "4  1       rec.sport.hockey     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     clean_text  \\\n",
       "0  Oh yeah how come Dino could never take the Caps out of the Patrick Division He choked up games to last year and got swept away in the second round two years ago He rarely if ever makes it out of the division So are the Islanders but they can still pull it out Vancouver has Winnipeg s number so it really doesn t matter Kings always seem to go at least or they never play a four or five game serious There s a difference between battling it out and pulling it out as I take Calgary to pull it out in                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "1  Does anyone know where Billy Taylor is Richmond or Syracuse He was taken by the Jays in the Rule V draft but not kept on the roster Baseball Weekly said that he was demoted to Syracuse but a Toronto paper indicated that the Braves took him back Is there an Atlanta fan or anyone reading this who knows                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "2  Why are you fooling around with analog for this job A single chip micro and a crystal will do the job reliably and easily An only costs about That and a crystal and you re in business Embed the whole thing in a foam insulated blanket power it from a solar cell use the excess power to heat the assembly during the day and rely on the insulation to hold the heat during darkness If you don t want to try thermal management contact someone like ICL and have them cut you a special low temperature crystal It ll cost at most If you use a single chip micro you re looking at a parts count of maybe A processor a crystal two caps on the crystal a power FET to fire the solenoid a flyback diode and a battery This is fewer parts than you can build an analog timer for and is infinitely more reliable Add a power zener diode for heat and a solar cell and the parts count screams up to PD assemblers are available for all the common single chip micros This application is so trivial you could even look up the op codes in the programmer s guide and create the binary with a hex editor John                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "3  Can anybody name a player who was rushed to the majors let s for argument s sake define rushed as brought up to the majors for more than a cup of coffee prior at age or younger and performing below expectations whose career was damaged by this rushing I m serious I tend to agree with David that bringing the player up sooner is better but I d like to look at players for whom this theory didn t work if there are any I d prefer players within the last years or so because then I can look up their minor league stats It s important to distinguish between players who legitimately had careers below what their minor league numbers would have projected as opposed to players who were hyped and failed but actually had careers not out of line with their minor league numbers Let s kick it off with an example of a player who was rushed although there doesn t seem to have been any damage to his career Jay Bell was given PAs in the major leagues at age and performed well below what you would expect from his AAA numbers the same season He got PAs the next year at age and still underperformed However the next year at age his performance improved and he won the everyday shortstop job and has been there ever since It s really hard for me to see where he would have been better off staying in the minor league where he was performed quite well in AAA during this time rather than being rushed Cleveland might have been better off I suppose because they might have been less likely to give up on him Yes if you bring a player up early he s likely going to struggle But does that delay the time at which he stops struggling and starts performing up to expectations   \n",
       "4  With Soderstrom and Roussel why the hell would the Flyers want to pick up an older and slumping Roy BYW I could come up with a group of players they d trade for but they wouldn t be from the same team                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               lemmas  \n",
       "0  [oh, yeah, come, Dino, cap, Patrick, Division, choke, game, year, get, sweep, away, second, round, year, ago, rarely, make, division, Islanders, pull, Vancouver, Winnipeg, s, number, doesn, t, matter, king, play, game, s, difference, battle, pull, Calgary, pull]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "1  [know, Billy, Taylor, Richmond, Syracuse, take, Jays, Rule, v, draft, keep, roster, Baseball, Weekly, say, demote, Syracuse, Toronto, paper, indicate, Braves, take, Atlanta, fan, read, know]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "2  [fool, analog, job, single, chip, micro, crystal, job, reliably, easily, cost, crystal, business, Embed, thing, foam, insulate, blanket, power, solar, cell, use, excess, power, heat, assembly, day, rely, insulation, hold, heat, darkness, don, t, want, try, thermal, management, contact, like, ICL, cut, special, low, temperature, crystal, will, cost, use, single, chip, micro, look, part, count, maybe, processor, crystal, cap, crystal, power, FET, fire, solenoid, flyback, diode, battery, few, part, build, analog, timer, infinitely, reliable, add, power, zener, diode, heat, solar, cell, part, count, scream, PD, assembler, available, common, single, chip, micro, application, trivial, look, op, code, programmer, s, guide, create, ...]  \n",
       "3  [anybody, player, rush, major, let, s, argument, s, sake, define, rush, bring, major, cup, coffee, prior, age, young, perform, expectation, career, damage, rush, m, tend, agree, David, bring, player, sooner, well, d, like, look, player, theory, didn, t, work, d, prefer, player, year, look, minor, league, stat, s, important, distinguish, player, legitimately, career, minor, league, number, project, oppose, player, hype, fail, actually, career, line, minor, league, number, let, s, kick, example, player, rush, doesn, t, damage, career, Jay, Bell, give, pas, major, league, age, perform, expect, AAA, number, season, get, pas, year, age, underperform, year, age, performance, improve, win, everyday, ...]                                  \n",
       "4  [Soderstrom, Roussel, hell, Flyers, want, pick, old, slump, Roy, BYW, come, group, player, d, trade, wouldn, t, team]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPuCuK0z3Lzs"
   },
   "source": [
    "### The two main inputs to the LDA topic model are the dictionary (id2word) and the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1klqRpqtJxWc"
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(df['lemmas'] )\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in df['lemmas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words do we have?\n",
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove extreme values from the dataset\n",
    "id2word.filter_extremes(no_below=5, no_above=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3358"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words do we have?\n",
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArZPxcP5LH1J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Message'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IIBnI2e3Lzw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK I m sure that this has been asked s of times before but I have wondered since I heard it Where the hell did the nickname of the Habs come from for the Montreal Canadiens'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGFG9E2j3Lzz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 1),\n",
       " (27, 1),\n",
       " (169, 1),\n",
       " (193, 1),\n",
       " (206, 1),\n",
       " (213, 1),\n",
       " (214, 1),\n",
       " (215, 1),\n",
       " (216, 1),\n",
       " (217, 1),\n",
       " (218, 1),\n",
       " (219, 1),\n",
       " (220, 1),\n",
       " (221, 1)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TB6wox963Lz2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Philadelphia'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[252]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kk3g75XX3Lz4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'White'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[276]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6K2jWxHJLOzK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('difference', 1),\n",
       " ('second', 1),\n",
       " ('Roy', 1),\n",
       " ('room', 1),\n",
       " ('Baltimore', 1),\n",
       " ('Chicago', 1),\n",
       " ('Cincinnati', 1),\n",
       " ('City', 1),\n",
       " ('Colorado', 1),\n",
       " ('Cubs', 1),\n",
       " ('DODGERS', 1),\n",
       " ('Detroit', 1),\n",
       " ('Diego', 1),\n",
       " ('Dodgers', 1)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[(id2word[word_id], word_count) for word_id, word_count in corpus[5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le-XzI923Lz8"
   },
   "source": [
    "# Part 2: Estimate a LDA Model with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AlNG4bSI3Lz8"
   },
   "source": [
    " ### Train an LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fasvjf0VLQ2a"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3358 is out of bounds for axis 1 with size 3358",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    978\u001b[0m                         \u001b[0mpass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_no\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m                     )\n\u001b[0;32m--> 980\u001b[0;31m                     \u001b[0mgammat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_estep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_alpha\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mdo_estep\u001b[0;34m(self, chunk, state)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msstats\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumdocs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# avoids calling len(chunk) on a generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mexpElogbetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;31m# The optimal phi_{dwk} is proportional to expElogthetad_k * expElogbetad_w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3358 is out of bounds for axis 1 with size 3358"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=20, \n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            per_word_topics=True)\n",
    "\n",
    "# https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49CabmIj3Lz_"
   },
   "outputs": [],
   "source": [
    "lda_model.save('lda_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDgUshRE3L0C"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-11:\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "Process ForkPoolWorker-12:\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-13:\n",
      "IndexError: index 3673 is out of bounds for axis 1 with size 3358\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "IndexError: index 3606 is out of bounds for axis 1 with size 3358\n",
      "Traceback (most recent call last):\n",
      "IndexError: index 6554 is out of bounds for axis 1 with size 3358\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "IndexError: index 3483 is out of bounds for axis 1 with size 3358\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "IndexError: index 3619 is out of bounds for axis 1 with size 3358\n",
      "Process ForkPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-15:\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "IndexError: index 3468 is out of bounds for axis 1 with size 3358\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-16:\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-5:\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "IndexError: index 3796 is out of bounds for axis 1 with size 3358\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "IndexError: index 5724 is out of bounds for axis 1 with size 3358\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "IndexError: index 12870 is out of bounds for axis 1 with size 3358\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "IndexError: index 3358 is out of bounds for axis 1 with size 3358\n",
      "IndexError: index 4123 is out of bounds for axis 1 with size 3358\n",
      "Process ForkPoolWorker-17:\n",
      "Process ForkPoolWorker-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "Process ForkPoolWorker-19:\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "IndexError: index 6943 is out of bounds for axis 1 with size 3358\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "IndexError: index 3371 is out of bounds for axis 1 with size 3358\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "IndexError: index 4046 is out of bounds for axis 1 with size 3358\n",
      "IndexError: index 3750 is out of bounds for axis 1 with size 3358\n",
      "Process ForkPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "Process ForkPoolWorker-22:\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamulticore.py\", line 337, in worker_e_step\n",
      "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
      "IndexError: index 3390 is out of bounds for axis 1 with size 3358\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 742, in do_estep\n",
      "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
      "  File \"/opt/anaconda3/envs/U4-S1-NLP/lib/python3.7/site-packages/gensim/models/ldamodel.py\", line 680, in inference\n",
      "    expElogbetad = self.expElogbeta[:, ids]\n",
      "IndexError: index 4025 is out of bounds for axis 1 with size 3358\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-26:\n",
      "Process ForkPoolWorker-33:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-27:\n",
      "Process ForkPoolWorker-24:\n",
      "Process ForkPoolWorker-28:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-29:\n",
      "Traceback (most recent call last):\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_multicore = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=20, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=12)\n",
    "\n",
    "# https://radimrehurek.com/gensim/models/ldamulticore.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rgb9AaPq3L0E"
   },
   "outputs": [],
   "source": [
    "lda_multicore.save('lda_multicore.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLxvJPoK3L0G"
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "lda_multicore =  models.LdaModel.load('lda_multicore.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDH3tzx13L0I"
   },
   "source": [
    "### View the topics in LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec.sport.baseball', 'rec.sport.hockey', 'sci.electronics']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JawR8yscLVNS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.009*\"people\" + 0.007*\"Israel\" + 0.006*\"government\" + 0.006*\"turkish\" + '\n",
      "  '0.006*\"armenian\" + 0.006*\"Jews\" + 0.006*\"right\" + 0.005*\"state\" + '\n",
      "  '0.005*\"Armenians\" + 0.005*\"israeli\"'),\n",
      " (1,\n",
      "  '0.005*\"antenna\" + 0.005*\"unit\" + 0.005*\"sphere\" + 0.005*\"74\" + 0.004*\"SI\" + '\n",
      "  '0.004*\"iranian\" + 0.003*\"garage\" + 0.003*\"Mark\" + 0.003*\"CPU\" + '\n",
      "  '0.003*\"plane\"'),\n",
      " (2,\n",
      "  '0.069*\"1\" + 0.043*\"maxaxaxaxaxaxaxaxaxaxaxaxaxaxax\" + 0.043*\"0\" + 0.042*\"2\" '\n",
      "  '+ 0.026*\"3\" + 0.021*\"4\" + 0.016*\"5\" + 0.014*\"7\" + 0.013*\"6\" + 0.011*\"25\"'),\n",
      " (3,\n",
      "  '0.029*\"not\" + 0.014*\"say\" + 0.013*\"go\" + 0.012*\"gun\" + 0.011*\"people\" + '\n",
      "  '0.010*\"know\" + 0.009*\"come\" + 0.009*\"s\" + 0.007*\"think\" + 0.007*\"tell\"'),\n",
      " (4,\n",
      "  '0.008*\"Center\" + 0.007*\"report\" + 0.006*\"patient\" + 0.006*\"1993\" + '\n",
      "  '0.005*\"Health\" + 0.005*\"April\" + 0.005*\"disease\" + 0.005*\"child\" + '\n",
      "  '0.005*\"increase\" + 0.005*\"University\"'),\n",
      " (5,\n",
      "  '0.005*\"irq\" + 0.004*\"fold\" + 0.003*\"MO\" + 0.003*\"overlap\" + 0.003*\"draw\" + '\n",
      "  '0.003*\"line\" + 0.003*\"skate\" + 0.003*\"airplane\" + 0.002*\"ray\" + '\n",
      "  '0.002*\"hidden\"'),\n",
      " (6,\n",
      "  '0.007*\"Q\" + 0.006*\"information\" + 0.005*\"list\" + 0.005*\"send\" + '\n",
      "  '0.004*\"include\" + 0.004*\"use\" + 0.004*\"President\" + 0.004*\"new\" + '\n",
      "  '0.004*\"program\" + 0.004*\"issue\"'),\n",
      " (7,\n",
      "  '0.016*\"Church\" + 0.009*\"Pope\" + 0.007*\"Catholic\" + 0.007*\"Gaza\" + '\n",
      "  '0.006*\"de\" + 0.005*\"van\" + 0.005*\"Sabbath\" + 0.005*\"CDI\" + '\n",
      "  '0.005*\"ceremonial\" + 0.004*\"bishop\"'),\n",
      " (8,\n",
      "  '0.013*\"Space\" + 0.013*\"550\" + 0.011*\"launch\" + 0.010*\"orbit\" + '\n",
      "  '0.009*\"mission\" + 0.009*\"space\" + 0.008*\"NASA\" + 0.008*\"satellite\" + '\n",
      "  '0.006*\"Earth\" + 0.006*\"probe\"'),\n",
      " (9,\n",
      "  '0.012*\"problem\" + 0.012*\"not\" + 0.011*\"window\" + 0.009*\"thank\" + '\n",
      "  '0.008*\"know\" + 0.008*\"use\" + 0.008*\"try\" + 0.007*\"work\" + 0.007*\"like\" + '\n",
      "  '0.006*\"have\"'),\n",
      " (10,\n",
      "  '0.015*\"not\" + 0.008*\"like\" + 0.007*\"time\" + 0.007*\"good\" + 0.006*\"think\" + '\n",
      "  '0.005*\"work\" + 0.005*\"know\" + 0.005*\"car\" + 0.005*\"have\" + 0.005*\"year\"'),\n",
      " (11,\n",
      "  '0.053*\"drive\" + 0.017*\"disk\" + 0.014*\"SCSI\" + 0.013*\"controller\" + '\n",
      "  '0.012*\"hard\" + 0.009*\"tape\" + 0.008*\"o\" + 0.008*\"IDE\" + 0.007*\"floppy\" + '\n",
      "  '0.007*\"system\"'),\n",
      " (12,\n",
      "  '0.013*\"file\" + 0.010*\"use\" + 0.008*\"program\" + 0.008*\"card\" + 0.008*\"run\" + '\n",
      "  '0.007*\"not\" + 0.007*\"image\" + 0.007*\"version\" + 0.006*\"software\" + '\n",
      "  '0.006*\"available\"'),\n",
      " (13,\n",
      "  '0.006*\"DoD\" + 0.006*\"argument\" + 0.006*\"militia\" + 0.005*\"Spirit\" + '\n",
      "  '0.005*\"ad\" + 0.005*\"Father\" + 0.004*\"Hawks\" + 0.004*\"fallacy\" + 0.004*\"Son\" '\n",
      "  '+ 0.004*\"cross\"'),\n",
      " (14,\n",
      "  '0.127*\"x\" + 0.043*\"X\" + 0.021*\"entry\" + 0.014*\"DB\" + 0.014*\"file\" + '\n",
      "  '0.009*\"program\" + 0.007*\"section\" + 0.006*\"rule\" + 0.005*\"n\" + '\n",
      "  '0.005*\"line\"'),\n",
      " (15,\n",
      "  '0.005*\"film\" + 0.005*\"prophecy\" + 0.004*\"280\" + 0.004*\"LEAGUE\" + 0.003*\"Gd\" '\n",
      "  '+ 0.003*\"Matthew\" + 0.003*\"gee\" + 0.003*\"ECHL\" + 0.003*\"Keith\" + '\n",
      "  '0.003*\"lets\"'),\n",
      " (16,\n",
      "  '0.022*\"game\" + 0.017*\"team\" + 0.016*\"not\" + 0.013*\"play\" + 0.013*\"year\" + '\n",
      "  '0.011*\"player\" + 0.010*\"good\" + 0.009*\"win\" + 0.008*\"think\" + '\n",
      "  '0.007*\"season\"'),\n",
      " (17,\n",
      "  '0.046*\"key\" + 0.018*\"chip\" + 0.016*\"encryption\" + 0.009*\"not\" + '\n",
      "  '0.009*\"phone\" + 0.009*\"use\" + 0.008*\"government\" + 0.008*\"algorithm\" + '\n",
      "  '0.008*\"number\" + 0.008*\"DES\"'),\n",
      " (18,\n",
      "  '0.009*\"Gordon\" + 0.008*\"homicide\" + 0.008*\"Banks\" + 0.007*\"soon\" + '\n",
      "  '0.007*\"surrender\" + 0.007*\"intellect\" + 0.007*\"shameful\" + 0.006*\"chastity\" '\n",
      "  '+ 0.006*\"Skepticism\" + 0.006*\"N3JXP\"'),\n",
      " (19,\n",
      "  '0.019*\"not\" + 0.010*\"people\" + 0.010*\"God\" + 0.010*\"think\" + 0.009*\"know\" + '\n",
      "  '0.007*\"believe\" + 0.007*\"say\" + 0.006*\"thing\" + 0.005*\"like\" + '\n",
      "  '0.005*\"time\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_multicore.print_topics())\n",
    "doc_lda = lda_multicore[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_multicore[corpus[5]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distro = [lda_multicore[d][0] for d in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "distro[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gKEP0bIC3L0K"
   },
   "source": [
    "### What is topic Perplexity?\n",
    "Perplexity is a statistical measure of how well a probability model predicts a sample. As applied to LDA, for a given value of , you estimate the LDA model. Then given the theoretical word distributions represented by the topics, compare that to the actual topic mixtures, or distribution of words in your documents.\n",
    "\n",
    "### What is topic coherence?\n",
    "Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference.\n",
    "A set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is “the game is a team sport”, “the game is played with a ball”, “the game demands great physical efforts”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xCjhr8k4LXSy"
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_multicore.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_multicore, \n",
    "                                     texts=df['lemmas'], \n",
    "                                     dictionary=id2word, \n",
    "                                     coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7UvfgYt93L0X"
   },
   "source": [
    "# Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYXi480VLaHK"
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_multicore, corpus, id2word)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjtXk8J3LaXC"
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=num_topics, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=12)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRA9EjvQ3L0c"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, \n",
    "                                                        corpus=corpus, \n",
    "                                                        texts=df['lemmas'], \n",
    "                                                        start=2, \n",
    "                                                        limit=40, \n",
    "                                                        step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2e9X-Ql-3L0e"
   },
   "outputs": [],
   "source": [
    "coherence_values = [0.5054, 0.5332, 0.5452, 0.564, 0.5678, 0.5518, 0.519]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybEBYQNF3L0g"
   },
   "outputs": [],
   "source": [
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmvQ2zKZ3L0i"
   },
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yol5vG3R3L0k"
   },
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "#optimal_model = model_list[4]\n",
    "optimal_model =  models.LdaModel.load('optimal_model.model')\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8HwVEUDI3L0m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSPT6_LS_DS_414_Topic_Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
